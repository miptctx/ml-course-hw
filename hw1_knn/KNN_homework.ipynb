{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979f14c3-bd74-4568-b0e1-0f2e6a867a81",
   "metadata": {},
   "source": [
    "Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c24561-ceb2-4abb-9e0f-f6fa902781e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "import scipy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from numpy.linalg import norm as numpy_euclidean_norm\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183c311-966e-4507-8d96-7c9cbd59f3de",
   "metadata": {},
   "source": [
    "Это оригинальный класс из файла практики, без каких-либо изменений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562e9d0c-c546-4d33-947b-d9e5d37f84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNVotingClassifier:\n",
    "    def __init__(self, k_neighbours: int, metric: str = 'euclidean'):\n",
    "        self._allowed_metrics = {\n",
    "            'euclidean': lambda x, y: numpy_euclidean_norm(x - y),\n",
    "        }\n",
    "        \n",
    "        assert metric in self._allowed_metrics, f\"Metric should be one of the {self._allowed_metrics.keys()}, got {metric}\"\n",
    "        \n",
    "        self._metric = self._allowed_metrics[metric]\n",
    "        self._k_neighbours = k_neighbours\n",
    "        \n",
    "        self._X, self._y = None, None\n",
    "    \n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        '''\n",
    "        When fit() method called -- model just saves the Xs and ys\n",
    "        '''\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        \n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        '''Non-optimized version (python loop-based)'''\n",
    "        \n",
    "        # Assertion check -- if model is fitted or not\n",
    "        assert (self._X is not None and self._y is not None), f\"Model is not fitted yet!\"\n",
    "        \n",
    "        ys_pred: np.array = np.zeros(shape=(X.shape[0], 1)) # Predictions matrix allocation\n",
    "            \n",
    "        '''\n",
    "        For each sample in X calculate distances to the points in self._X, using the self._metric()\n",
    "        calculate distances and get K nearest points. \n",
    "        '''\n",
    "        for sample_id, X_this in enumerate(X):\n",
    "            distances: List = []\n",
    "            \n",
    "            for train_id, X_other in enumerate(self._X):\n",
    "                distance = np.log(self._metric(X_this, X_other))\n",
    "                distances.append({\n",
    "                    'train_id': train_id,\n",
    "                    'distance': distance,\n",
    "                })\n",
    "            sorted_distances: List = self._sort_distances(distances)\n",
    "            y_pred: int = self._get_nearest_class(sorted_distances)\n",
    "            ys_pred[sample_id] = y_pred\n",
    "\n",
    "        return ys_pred\n",
    "     \n",
    "    @staticmethod\n",
    "    def _sort_distances(distances: List, ascending=False) -> List:\n",
    "        return sorted(distances, key=lambda x: x['distance'], reverse=ascending)\n",
    "    \n",
    "    def _get_nearest_class(self, sorted_distances: list) -> int:\n",
    "        sorted_distances_top_k: List = sorted_distances[:self._k_neighbours]\n",
    "        labels_top_k: List = [self._y[sample['train_id']] for sample in sorted_distances_top_k]\n",
    "        predicted_label: int = self._decision_rule(labels_top_k)\n",
    "        return predicted_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def _decision_rule(labels_top_k: List) -> int:\n",
    "        labels_count_top_k = Counter(labels_top_k) # {label_1: label_1_num_occurences, ...}\n",
    "        sorted_labels_count_top_k: List = sorted(labels_count_top_k.items(), \n",
    "                                                 key=lambda x: x[1], \n",
    "                                                 reverse=True)\n",
    "        predicted_label: int = sorted_labels_count_top_k[0][0]\n",
    "        return predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ff0c4-0dde-4d89-9074-58a615e5c5b1",
   "metadata": {},
   "source": [
    "Это модифицированный класс в котором учитывается вес каждого соседа в зависимости от дистанции по формуле $$weight*\\frac{k-i}{k}$$. Т.е. это решение к первой задаче без звездочки. Я наследовал этот класс от того, который был в примере и переопредилил метод `predict()`. Этот класс работает довольно медленно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4c991b-990f-4c88-bb69-1b0361e16bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_train_id = 'train_id'\n",
    "str_distance = 'distance'\n",
    "\n",
    "\n",
    "class KNNVotingClassifierWithWeight(KNNVotingClassifier):\n",
    "    def __init__(self, k_neighbours: int, metric: str = 'euclidean', weight_samples=False):\n",
    "        super().__init__(k_neighbours, metric)\n",
    "        self.weight_samples = weight_samples\n",
    "\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        '''Non-optimized version (python loop-based)'''\n",
    "        \n",
    "        # Assertion check -- if model is fitted or not\n",
    "        assert (self._X is not None and self._y is not None), f\"Model is not fitted yet!\"\n",
    "        \n",
    "        ys_pred: np.array = np.zeros(shape=(X.shape[0], 1)) # Predictions matrix allocation\n",
    "\n",
    "        '''\n",
    "        For each sample in X calculate distances to the points in self._X, using the self._metric()\n",
    "        calculate distances and get K nearest points. \n",
    "        '''\n",
    "        for sample_id, X_this in enumerate(X):\n",
    "            distances: List = []\n",
    "            \n",
    "            for train_id, X_other in enumerate(self._X):\n",
    "                distance = self._metric(X_this, X_other)\n",
    "                distances.append({\n",
    "                    str_train_id: train_id,\n",
    "                    str_distance: distance,\n",
    "                })\n",
    "            sorted_distances: List = self._sort_distances(distances)\n",
    "            y_pred: int = self._get_nearest_class(sorted_distances) if not self.weight_samples else self._get_nearest_class_weigth(sorted_distances)\n",
    "            ys_pred[sample_id] = y_pred\n",
    "\n",
    "        return ys_pred\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_distance(value, idx, total):\n",
    "        return value*(total + 0 - idx)/total\n",
    "\n",
    "    def _get_nearest_class_weigth(self, sorted_distances: list) -> int:\n",
    "        sorted_distances_top_k: List = sorted_distances[:self._k_neighbours]\n",
    "        sorted_distances_top_k_weight = [\n",
    "            {\n",
    "                str_distance: self.fix_distance(item[str_distance], idx, len(sorted_distances_top_k)),\n",
    "                str_train_id: item[str_train_id]\n",
    "            }\n",
    "            for idx, item in enumerate(sorted_distances_top_k)\n",
    "        ]\n",
    "\n",
    "        predicted_train_id: int = self._decision_rule_weight(sorted_distances_top_k_weight)\n",
    "        return self._y[predicted_train_id]\n",
    "\n",
    "    @staticmethod\n",
    "    def _decision_rule_weight(distances: List) -> int:\n",
    "        distances_weights = {}\n",
    "        for item in distances:\n",
    "            if item[str_train_id] in distances_weights:\n",
    "                distances_weights[item[str_train_id]] += item[str_distance]\n",
    "            else:\n",
    "                distances_weights[item[str_train_id]] = item[str_distance]\n",
    "\n",
    "        distances_weights_sorted = sorted(distances_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "        return distances_weights_sorted[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e198f-13f4-45a1-a1d0-d5cdd0c59500",
   "metadata": {},
   "source": [
    "Далее идут несколько классов по задаче со звездочкой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce875f1e-2866-4ed8-83ae-ca45e566475a",
   "metadata": {},
   "source": [
    "Самое первое, что пришло в голову, это пройтись по всем элементам тестовой выборки и почти в тупую посчитать расстояние до всех элементов тренировочной выборки.\n",
    "\n",
    "Почти в тупую означает, что я считаю расстояния не в отдельном цикле, как в предыдущем классе, а с помощью бродкастинга, получая т.о. сразу целую матрицу расстояний для i-го элемента. Коррекция расстояний с помощью весов тоже происходит с помощью бродкастинга.\n",
    "\n",
    "Этот класс работает немного быстрее чем предыдущий, но не значительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ebafa8-870d-47d1-ba40-d4607eedc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedKNNClassifier(KNNVotingClassifierWithWeight):\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        ys_pred: np.array = np.zeros(shape=(X.shape[0], 1)) # Predictions matrix allocation\n",
    "\n",
    "        distances = []\n",
    "        total = len(X)\n",
    "        for sample_id, row in enumerate(X):\n",
    "            sys.stdout.write(f\"\\r\\tprocessed {sample_id} rows from {total} \\t \" + \"{:.2f}\".format(sample_id*100/total) + \"%                    \")\n",
    "            \n",
    "            # calculate matrix of all distances between current tested point and all other trained points, broadcasting is made here\n",
    "            distances = self._X - row\n",
    "\n",
    "            # calc frobenius norm for each row\n",
    "            distances = np.linalg.norm(distances, axis=1)\n",
    "\n",
    "            # enumerate distances to keep their current indexes and sort\n",
    "            sorted_distances = sorted(enumerate(distances), key=lambda x: x[1])[:self._k_neighbours]\n",
    "\n",
    "            # select our nearest neighbours\n",
    "            k_neighbours = np.array(list(map(lambda x: x[1], sorted_distances)))\n",
    "\n",
    "            # select our k nearest neighbours\n",
    "            neighbours_idx = np.arange(self._k_neighbours)\n",
    "\n",
    "            # calculate weigts depending on their index,\n",
    "            # i.e. calculate weighted distances;\n",
    "            # a little breadcasting is made here again\n",
    "            k_neighbours = k_neighbours*(self._k_neighbours - neighbours_idx)/self._k_neighbours\n",
    "\n",
    "            # count most weighted target between our k neighbours\n",
    "            counts = {}\n",
    "            for i, weight in enumerate(k_neighbours):\n",
    "                target = self._y[sorted_distances[i][0]]\n",
    "                if target in counts:\n",
    "                    counts[target] += weight\n",
    "                else:\n",
    "                    counts[target] = weight\n",
    "\n",
    "            # save predicted feature value\n",
    "            ys_pred[sample_id] = sorted(counts.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "        sys.stdout.write(f\"\\r\\tprocessed 100%                                         \\n\")\n",
    "        return ys_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e82520-cf37-49b3-9294-28c187bab649",
   "metadata": {},
   "source": [
    "Намного более хорошего результата удалось получить после того, как я узнал про функцию cdist пакета scipy, которая умеет считать сразу все расстояний для всех элементов тестовой выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4db87-51b0-40a4-bcc2-6f63dbe0ab3d",
   "metadata": {},
   "source": [
    "В этом классе я получаю матрицу расстояний, транспонирую ее чтобы строками были элементы тестовой выборки, потом прохожу по каждой строчке, получаю всех требуемых близких соседей, корректирую их расстояния с помощью весов и потом суммирую расстояния для всех типов соседей данного элемента. Получилось очень быстро, намного быстрее, чем предыдущий класс, хотя и приблизительно в два раза медленнее чем реализация sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb45190-49c2-43e7-837a-25433f0847ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CdistOptimizedKNNClassifier(KNNVotingClassifierWithWeight):\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        ys_pred: np.array = np.zeros(shape=(X.shape[0], 1)) # Predictions matrix allocation\n",
    "\n",
    "        total = len(X)\n",
    "\n",
    "        all_distances = np.transpose(scipy.spatial.distance.cdist(self._X, X))\n",
    "\n",
    "        for sample_id, distances in enumerate(all_distances):\n",
    "            sys.stdout.write(f\"\\r\\tprocessed {sample_id} rows from {total} \\t \" + \"{:.2f}\".format(sample_id*100/total) + \"%                    \")\n",
    "\n",
    "            # enumerate all distances to save their current id and sort items\n",
    "            sorted_distances = sorted(enumerate(distances), key=lambda x: x[1])[:self._k_neighbours]\n",
    "            # print(\"sorted_distances\\n\", sorted_distances)\n",
    "\n",
    "            # select our k nearest neighbours\n",
    "            k_neighbours = np.array(list(map(lambda x: x[1], sorted_distances)))\n",
    "            neighbours_idx = np.arange(self._k_neighbours)\n",
    "\n",
    "            # calculate weigts depending on their index,\n",
    "            # i.e. calculate weighted distances;\n",
    "            # a little breadcasting is made here again\n",
    "            k_neighbours = k_neighbours*(self._k_neighbours - neighbours_idx)/self._k_neighbours\n",
    "\n",
    "            # count most weighted target between our k neighbours\n",
    "            counts = {}\n",
    "            for i, weight in enumerate(k_neighbours):\n",
    "                target = self._y[sorted_distances[i][0]]\n",
    "                if target in counts:\n",
    "                    counts[target] += weight\n",
    "                else:\n",
    "                    counts[target] = weight\n",
    "\n",
    "            # save predicted feature value\n",
    "            ys_pred[sample_id] = sorted(counts.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "        sys.stdout.write(f\"\\r\\tprocessed 100%                                         \\n\")\n",
    "        return ys_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f37ece-1907-4d48-86e5-456e18c154e6",
   "metadata": {},
   "source": [
    "Поэтому я модифицировал последний класс, убрав из него транспонирование всей матрицы расстояний и осуществив обход этой матрицы по столбцам. В этом мне помогла функция `numpy.argsort`, которая возвращает индексы элементов в том порядке, в котром они бы располагались при сортировке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb41e12-a503-462b-815b-a1e123d8854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CdistOptimizedKNNClassifier2(KNNVotingClassifierWithWeight):\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        ys_pred: np.array = np.zeros(shape=(X.shape[0], 1)) # Predictions matrix allocation\n",
    "\n",
    "        # calculate distances between test and train items\n",
    "        all_distances = scipy.spatial.distance.cdist(self._X, X)\n",
    "\n",
    "        # get sorted indexes of calculated distances\n",
    "        k_nearest_neighbours_idx = np.argsort(all_distances, axis=0)[:self._k_neighbours,:]\n",
    "\n",
    "        columns = k_nearest_neighbours_idx.shape[1]\n",
    "        # iterate by each tested item\n",
    "        for column in range(columns):\n",
    "            sys.stdout.write(f\"\\r\\tprocessed {column} columns from {columns} \\t \" + \"{:.2f}\".format(column*100/columns) + \"%                    \")\n",
    "\n",
    "            # select column of nearest neighbours\n",
    "            nearest_neighbours_distances = all_distances[:,column][k_nearest_neighbours_idx[:,column]]\n",
    "\n",
    "            # generated indexes for our nearest neighbours\n",
    "            k_nearest_neighbours_arranged = np.transpose(np.arange(self._k_neighbours))\n",
    "\n",
    "            # calculate weigts depending on their index,\n",
    "            # i.e. calculate weighted distances;\n",
    "            # a little breadcasting is made here\n",
    "            nearest_neighbours_distances_weighted = nearest_neighbours_distances*(self._k_neighbours - k_nearest_neighbours_arranged)/self._k_neighbours\n",
    "\n",
    "            # count most weighted targets between our k neighbours\n",
    "            counts = {}\n",
    "            targets = self._y[k_nearest_neighbours_idx[:,column]]\n",
    "            for i in k_nearest_neighbours_arranged:\n",
    "                weight = nearest_neighbours_distances_weighted[i]\n",
    "                target = targets[i]\n",
    "                if target in counts:\n",
    "                    counts[target] += weight\n",
    "                else:\n",
    "                    counts[target] = weight\n",
    "\n",
    "            # save predicted target value\n",
    "            ys_pred[column] = sorted(counts.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "        sys.stdout.write(f\"\\r\\tprocessed 100%                                         \\n\")\n",
    "        return ys_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342a362-e9e8-4d70-9195-7120a61595d1",
   "metadata": {},
   "source": [
    "Данный класс получился очень быстрый. Он работал даже быстрее sklearn на моем компьютере и выдавал лучшее значение accuracy, когда я запускал питоновский скрипт напрямую через интерпретатор:\n",
    "```\n",
    "test cdist v2 optimized:\n",
    "\tprocessed 100%                                                     \n",
    "\taccuracy: 0.9741428571428571\n",
    "\telapsed time:  248.617237\n",
    "test cdist optimized:\n",
    "\tprocessed 100%                                             \n",
    "\taccuracy: 0.9741428571428571\n",
    "\telapsed time:  483.015303\n",
    "test sklearn:\n",
    "\taccuracy: 0.9661428571428572\n",
    "\telapsed time:  360.874690\n",
    "```\n",
    "\n",
    "В юпитере результат получается немного другой. В зависимости от количества данных, то этот класс по прежнему быстрее склерна, но акураси немного ниже начиная с тысячных, то акураси выше начиная с сотых, но быстродействие на одну десятую секунды ниже. Но по мере увеличения количества данных, этот класс начинает выигрывать и по времени и по акураси у склерна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf78671-5014-4756-8c7e-894d1cf3cf90",
   "metadata": {},
   "source": [
    "Код для запуска и проверки классов получился такой. Для того, чтобы получить ответ быстрее я сделал срез датасетов. Но этот срез можно увеличить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887689c2-d2b8-4ed4-b332-09ea719af87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "iris_dataset = datasets.load_iris()\n",
    "features = iris_dataset.data\n",
    "target = iris_dataset.target\n",
    "np.random.seed(2)\n",
    "X_train, y_train, X_test, y_test = train_test_split_data(features, target)\n",
    "'''\n",
    "\n",
    "features, target = datasets.fetch_openml(\"mnist_784\", parser='auto', return_X_y = True, as_frame=False)\n",
    "### NOTE: change slice values if you need test bigest/smaller data set\n",
    "features = features[:12000]\n",
    "target = target[:12000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(features, target, test_size = 0.10, random_state = 42)\n",
    "\n",
    "y_train = np.array(y_train).astype('uint8')\n",
    "y_test = np.array(y_test).astype('uint8')\n",
    "\n",
    "\n",
    "k_neighbours = 5\n",
    "\n",
    "knn_voting_clf_sklern = KNeighborsClassifier(10, metric='euclidean', algorithm='brute')\n",
    "knn_voting_clf_example = KNNVotingClassifier(k_neighbours)\n",
    "knn_voting_clf_custom = KNNVotingClassifierWithWeight(k_neighbours, weight_samples=True)\n",
    "knn_voting_clf_weight_optimized = OptimizedKNNClassifier(k_neighbours)\n",
    "knn_voting_clf_weight_cdist = CdistOptimizedKNNClassifier(k_neighbours)\n",
    "knn_voting_clf_weight_cdist_2 = CdistOptimizedKNNClassifier2(k_neighbours)\n",
    "\n",
    "def do_prediction(predictor, X_train, y_train, X_test, y_test):    \n",
    "    import time\n",
    "    t = time.process_time()\n",
    "\n",
    "    predictor.fit(X_train, y_train)\n",
    "    y_pred = predictor.predict(X_test)\n",
    "\n",
    "    elapsed_time = time.process_time() - t\n",
    "\n",
    "    # print(f\"predicted result: {y_pred.squeeze()}\")\n",
    "\n",
    "    accuracy = np.count_nonzero(y_test == y_pred.squeeze()) / y_test.shape[0]\n",
    "    print(f\"\\taccuracy: {accuracy}\")\n",
    "    print(f\"\\telapsed time: \", \"{:.6f}\".format(elapsed_time))\n",
    "\n",
    "def test_sklearn():\n",
    "    print(\"test sklearn:\")\n",
    "    do_prediction(knn_voting_clf_sklern, X_train, y_train, X_test, y_test)\n",
    "\n",
    "def test_example():\n",
    "    print(\"test example:\")\n",
    "    do_prediction(knn_voting_clf_example, X_train, y_train, X_test, y_test)\n",
    "\n",
    "def test_custom():\n",
    "    print(\"test custom:\")\n",
    "    do_prediction(knn_voting_clf_custom, X_train, y_train, X_test, y_test)\n",
    "\n",
    "def test_optimized():\n",
    "    print(\"test optimized:\")\n",
    "    do_prediction(knn_voting_clf_weight_optimized, X_train, y_train, X_test, y_test)\n",
    "\n",
    "def test_cdist():\n",
    "    print(\"test cdist optimized:\")\n",
    "    do_prediction(knn_voting_clf_weight_cdist, X_train, y_train, X_test, y_test)\n",
    "\n",
    "def test_cdist_2():\n",
    "    print(\"test cdist v2 optimized:\")\n",
    "    do_prediction(knn_voting_clf_weight_cdist_2, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "test_cdist_2()\n",
    "test_cdist()\n",
    "test_sklearn()\n",
    "test_optimized()\n",
    "test_custom()\n",
    "test_example()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
